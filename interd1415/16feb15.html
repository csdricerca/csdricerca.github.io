<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
  <meta http-equiv="CONTENT-TYPE" content="text/html; charset=UTF-8">
  <title>16feb15</title>
  <meta name="GENERATOR" content="OpenOffice 4.1.1  (Win32)">
  <meta name="AUTHOR" content="sergio ">
  <meta name="CREATED" content="20150303;9083200">
  <meta name="CHANGEDBY" content="Sergio Parenti">
  <meta name="CHANGED" content="20150723;17413135">
  <style type="text/css">
	<!--
		@page { margin: 2cm }
		P { margin-bottom: 0.21cm }
		P.sdfootnote { margin-left: 0.6cm; text-indent: -0.6cm; margin-bottom: 0cm; font-size: 10pt }
		A.sdfootnoteanc { font-size: 57% }
	-->
	</style>
</head>
<body dir="ltr" lang="it-IT">
<p style="margin-bottom: 0cm; font-style: normal; font-weight: normal;"
 align="left">
Bologna, 3 febbraio 2015</p>
<p style="margin-bottom: 0cm; font-style: normal; font-weight: normal;"
 align="left">
<br>
</p>
<p style="margin-bottom: 0cm;" align="right"><font size="3">Agli amici
degli</font></p>
<p style="margin-bottom: 0cm; font-style: normal; font-weight: normal;"
 align="right">
<font size="3">Incontri Interdisciplinari</font></p>
<p style="margin-bottom: 0cm; font-style: normal; font-weight: normal;"
 align="left">
<br>
</p>
<p style="margin-bottom: 0cm; font-style: normal; font-weight: normal;"
 align="left">
<br>
</p>
<p style="page-break-before: auto;" align="left"><big><font
 face="Times New Roman, serif"><font size="3"><big>Carissimi,</big></font></font></big></p>
<p style="font-style: normal; font-weight: normal;" align="left"><big><font
 face="Times New Roman, serif"><font size="3"><big> ci
rivedremo <b>lune</b><b>dì 16 febbraio</b>, alle <b>ore 21</b>,
presso il Convento San Domenico, che ci ospiterà nella sua
“<b>sala rossa</b>”, cui si accede da Via San Domenico 1.</big></font></font></big></p>
<p style="font-style: normal; font-weight: normal;" align="left"><big><font
 face="Times New Roman, serif"><font size="3"><big> La
volta scorsa abbiamo proseguito la ricerca su "la persona
umana"dal punto di vista della psichiatria e delle neuroscienze.
Questo ci ha portati a desiderare di conoscere meglio il punto di
vista di discipline come l'Intelligenza Artificiale ed altre affini.</big></font></font></big></p>
<p style="font-style: normal; font-weight: normal;" align="left"><big><font
 face="Times New Roman, serif"><font size="3"><big>Ci
introdurrà l'ing. <b>Fabio Frattini</b>, che ringrazio a nome
di tutti. L'argomento sarà</big></font></font></big></p>
<p style="font-style: normal; font-weight: normal;" align="center"><big><font
 face="Times New Roman, serif"><font size="3"><big><b>"atto
riflesso e coscienza"</b>.</big></font></font></big></p>
<p style="font-style: normal; font-weight: normal;" align="left"><big><br>
<br>
</big></p>
<p style="font-style: normal; font-weight: normal;" align="left"><big><font
 face="Times New Roman, serif"><font size="3"><big> Un
cordiale saluto in attesa di rivederci </big></font></font>
</big></p>
<p style="font-style: normal; font-weight: normal;" align="left"><big><br>
<br>
</big></p>
<p style="font-style: normal; font-weight: normal; text-align: center;"><big><font
 face="Times New Roman, serif"><font size="3"><big> <i>fra
Sergio Parenti O.P.</i></big></font></font></big></p>
<p style="font-style: normal; font-weight: normal;" align="left"><font
 face="Times New Roman, serif"><font size="3">______________________________________</font></font></p>
<p style="font-weight: normal;" align="left"><br>
<br>
</p>
<p align="center"><font size="3"><b>Breve resoconto dell'incontro
Interdisciplinare del 16 febbraio 2015</b></font></p>
<p align="center"><font size="3"><i>a cura di fra Sergio Parenti O.P.</i></font></p>
<p><br>
<br>
</p>
<p><font size="3">FRATTINI – Il nostro argomento è molto
tecnico e non si addice ad una discussione tra amici, perché
se si scende nel dettaglio non si capisce più niente. Si
sarebbe dovuto fare un discorso più generale sull'intelligenza
artificiale, di cui le reti neurali sono una parte. Ma anche questo è
un discorso che si interseca con la filosofia della mente, con tante
opinioni. Quest'ultimo argomento dovrebbe diventare oggetto di una
serata ulteriore.</font></p>
<p><font size="3">L'intelligenza artificiale si divide, grosso modo, in
due filoni: i sistemi esperti e le reti neuronali. I sistemi esperti
sono semplicemente programmi di computer che da un punto di vista
esclusivamente funzionale cercano di riprodurre un ragionamento
umano. I programmi imparano dall'esperienza (input) e supportano
decisioni. Questi programmi sono tutt'ora applicati. Le reti
neuronali cercano invece di imitare il funzionamento del cervello
umano. </font>
</p>
<p><font size="3">Che cos'è un neurone? Questa cellula presenta
molte ramificazioni: è predisposta per collegarsi con altre
cellule con molti terminali di input ed un solo output, che però
si può ramificare. I primi si chiamano dendriti, il secondo si
chiama assone. Il corpo della cellula è il soma. Come avviene
il collegamento con gli altri? L'assone intercetta un dendrite e si
collega ad esso tramite un oggetto che si chiama sinapsi, che
consente un meccanismo elettrochimico di trasmissione di
informazione. I collegamenti formano una rete molto complessa. Il
corpo cellulare esegue una “sommatoria” (sembra che
avvenga non in modo continuo, ma per impulsi): una sommatoria dei
segnali di ingresso. Se il risultato supera una certa soglia, il
neurone si attiva e produce un potenziale d'azione che esce
dall'assone; altrimenti rimane inerte. Una rete neurale descrive una
popolazione di neuroni fisicamente interconnessi tra loro o un gruppo
di neuroni che definiscano un circuito riconoscibile.</font></p>
<p><font size="3">Il funzionamento della cellula viene imitato da un
dispositivo elettronico, anche se la definizione di “neurone
artificiale” è puramente matematica. Il funzionamento
biologico della cellula nervosa assomiglia, nel grafico, ad una curva
sigmoide, che ricorda un cambiamento di stato, simile a quello
operato da un flip-flop, circuito elettronico, che però ha un
cambiamento con solo due stati (0, 1), mentre la sigmoide ha tutti
gli stati intermedi.</font></p>
<p><font size="3">Per imitare il comportamento della cellula nervosa si
è ricorsi ad un oggetto matematico (neurone matematico). Una
rete neurale artificiale è un modello matematico-informatico
di calcolo basato sulle reti neurali biologiche. Tale modello è
costituito da un gruppo di interconnessioni di informazioni
costituite da neuroni artificiali e processi che utilizzano un
approccio di connessioni di calcolo. Una rete neurale artificiale è,
per lo più, un sistema adattivo che cambia la sua struttura
basata su informazioni esterne o interne che scorrono attraverso la
rete durante le fasi di apprendimento. Le reti neurali sono strutture
non-lineari di dati statistici organizzate come strumenti di
modellazione. Non-lineari vuol dire che non sono riducibili ad una
espressione matematica reversibile: se vado da A a B non è
detto che possa tornare ad A. Esse sono utilizzate per simulare
relazioni complesse tra ingressi e uscite non rappresentabili dalle
comuni funzioni analitiche.</font></p>
<p><font size="3">McCulloch e Pitts sono stati i primi (1943: <i>A
logical calculus of the ideas immanent in nervous activity</i>) a
schematizzare un combinatore lineare a soglia, con dati multipli (può
avere tanti ingressi quanti i dendriti). Un insieme di segnali è
chiamato “vettore”. In algebra un inseme di valori
coerenti è un vettore, in informatica un vettore <i>x</i> è
una catasta di valori che la <i>x</i> può assumere (sono
valori discreti, non continui). Un numero opportuno di tali elementi,
connessi in una rete, è in grado di calcolare semplici
funzioni booleane(AND, OR).</font></p>
<p><font size="3">Prendiamo uno schema.</font></p>
<p align="center"><img src="16feb15_html_m31b42905.png"
 name="Immagine 44" align="bottom" border="0" height="119" width="343"></p>
<p><font size="3">La cosa importante è il peso: nella
connessione, cioè nella sinapsi, si può definire un
“peso”, da 0 a 1, che è l'efficienza di
trasmissione del segnale in ingresso. Questi pesi vanno moltiplicati
per i rispettivi segnali, il tutto viene integrato dal corpo del
neurone tramite una sommatoria, dopo di che c'è l'uscita
(U=1,75). Poiché la soglia è uguale a 1, quello che
viene propagato è l'eccesso (0,75). Questo segnale non è
0 o 1, ma posso considerarlo non digitale in senso stretto.</font></p>
<p><font size="3">Nella rete tutte le combinazioni hanno un certo peso
e contribuiscono al collegamento ingresso – uscita.</font></p>
<p><font size="3">Il fatto che le sinapsi abbiano un peso con valori
che possono cambiare mi permette di ipotizzare una rete capace di
apprendere. L'apprendimento consisterebbe nel modificare il
comportamento di una rete modificando il peso delle sinapsi.</font></p>
<p><font size="3">Le prime ipotesi di apprendimento furono introdotte
nel 1949 da uno studioso del cervello, Hebb, che aveva notato come
nel cervello si stabilissero tra le cellule quei collegamenti che in
qualche modo costituivano un premio: questo premio porta a creare
stati stabili all'interno dei collegamenti tra le cellule del
cervello. Hebb proponeva che qualcosa del genere venisse introdotto
nelle reti neuronali.</font></p>
<p><font size="3">Nel 1958 Von Neumann (<i>The computer and the brain</i><span
 style="font-style: normal;">)
esaminò le varie soluzioni proposte, sottolineandone la scarsa
precisione. Nello stesso anno Rosenblatt </span><i>(Psycological
review</i><span style="font-style: normal;">) introdusse il primo
schema di rete neurale: il Perceptron (percettrone), per il
riconoscimento e la classificazione di forme, allo scopo di fornire
un'interpretazione dell'organizzazione generale dei sistemi
biologici. Il suo modello matematico probabilistico è mirato
all'analisi di funzioni quali l'immagazzinamento delle informazioni e
della loro influenza sul riconoscimento dei pattern (le trame).
Quando ho una trama (ad esempio un disegno o uno schema: questo è
un pattern). Ad esempio il riconoscimento dei caratteri di uno
scritto (con un OCR) è un riconoscimento di pattern. I pesi
delle sinapsi sono variabili e quindi il percettrone è in
grado di apprendere. Nel 1969 Minsky e Papert (</span><i>An
introduction to computational geometry</i><span
 style="font-style: normal;">)
mostrano i limiti delle semplici reti a due strati basate sul
percettrone: questo tipo di rete neurale non è abbastanza
potente e non riesce neanche a calcolare la funzione </span><i>or
esclusivo</i> <span style="font-style: normal;">(XOR). Ne seguì
un periodo di diffidenza e negli USA furono sospesi i finanziamenti a
queste ricerche. Nel 1974 Werbos, matematico americano, risolse il
problema; ma solo tempo dopo, grazie ad uno studio del Hopfield
(1982), si riaprì la ricerca.</span></font></p>
<p style="font-style: normal;"><font size="3">Il modello di rete a due
strati, neuroni di ingresso e neuroni di uscita, era quello
criticato.</font></p>
<p style="font-style: normal;"><font size="3">PARENTI – Se ricordo
bene Wittgenstein, le funzioni logiche sono tutte equivalenti. Se non
calcola l' or esclusivo, non calcola neppure le altre.</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI – Non mi
pare: la funzione END, ad esempio, la faceva. Uno degli aspetti più
importanti era l'addestramento della rete. Mettendo uno strato
intermedio, nascosto, nascono vari tipi di rete possibili. Ogni
neurone è collegato con tutti gli altri, almeno
indirettamente. Lo strato intermedio si occupa dell'elaborazione vera
e propria, mentre lo strato iniziale e quello finale si occupano
della gestione dei dati: come presentarli nell'output e come
presentarli alla rete nell'ingresso. Posso fare reti che svolgano una
funzione limitata. Poi posso collegarli per avere una super-rete. La
frenologia cercò di associare parti del cervello a funzioni
specifiche. Questa diventa una specie di frenologia, ma per risolvere
problemi ingegneristici, tecnici, anche se la tentazione di farne una
metafora del cervello è molto forte, ma riguarda la filosofia
della mente. Noi ora parliamo di un oggetto tecnico.</font></p>
<p style="font-style: normal;"><font size="3">L'addestramento della
rete
avviene tramite il cambiamento dei pesi delle sinapsi per svolgere
una certa funzione. Ad esempio, un problema di classificazione è
riconoscere, per l'OCR, una “ni” senza confonderla con
una “m”. Il più applicato è l'apprendimento
“supervisionato”: costringere la rete, dato un certo
vettore di segnali di ingresso, a dare un certo vettore di segnali di
uscita. L'algoritmo di “backpropagation” calcola una
funzione di errore tra l'output ottenuto e quello che ci aspettiamo,
e va a correggere i pesi delle connessioni con una certa forma di
retroazione. Il paradigma di apprendimento “non supervisionato”
ha un addestramento che invece si riferisce solo ai dati di ingresso
per modificare i pesi; i problemi di ottimizzazione vengono
affrontati in questo modo: in questi problemi non abbiamo dati di
uscita previsti. Nell'apprendimento “per rinforzo” un
opportuno algoritmo si prefigge lo scopo di individuare un certo modo
di operare a partire da un processo di osservazione dell'ambiente
esterno. Ogni azione ha un impatto sull'ambiente che produce una
retroazione che guida l'algoritmo stesso nel processo
d'apprendimento. Questo apprendimento differisce da quello
“supervisionato” perché non sono mai presentate
coppie di input-output di esempi noti. Questo è il caso tipico
di quando devo guidare un veicolo alla cieca. Occorre un agente con
sensori che danno dei dati e devo confrontare continuamente i dati
elaborati con i dati che di nuovo mi restituisce l'ambiente.
L'ambiente è continuamente fonte di dati ed io scelgo i dati
giusti quando i dati concordano. Sono uscite delle auto che hanno una
guida automatica.</font></p>
<p style="font-style: normal;"><font size="3">GRAGNANO – C'è
un riferimento messo da chi ha fatto la rete e vengono rinforzati
solo i dati dove concordano le cose che io cerco con quelle che mi dà
la rete.</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI – Esatto.
Vi è poi l'apprendimento “hebbiano” (da Hebb): se
due neuroni si attivano contemporaneamente, la loro connessione deve
essere rafforzata. Se un collegamento corrisponde a certi criteri,
viene premiato, fino a rendere stabili certe connessioni. Altrimenti
le connessioni si indeboliscono.</font></p>
<p style="font-style: normal;"><font size="3">GRAGNANO – Certi
input modificano la funzione. Cambiando i pesi non cambia quello che
c'è in mezzo tra input e output?</font></p>
<p style="font-style: normal;"><font size="3">CASADIO – Cambia il
valore di quella funzione, non la funzione. Se non sei soddisfatto
perché il valore in output non coincide col valore atteso,
torni indietro e correggi il valore dei pesi finché non ti
coincide. L'input è tutto sommato fisso, e l'output è
atteso. Questo viene posto dall'esterno.</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI – Gli
algoritmi sono fatti da ingegneri, o meglio da dei matematici,
trattandosi di oggetti matematici.</font></p>
<p style="font-style: normal;"><font size="3">CASADIO – Sono
algoritmi non convenzionali. Il backpropagation supervisionato
permette di trovare se ci sono relazioni tra degli input e degli
output, se non sei in grado di trovare la funzione analitica di
supporto. Esiste un'altra categoria di reti neuronali non
supervisionate, dove l'algoritmo devi trovarlo tu.</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI – Quando
non so dove si andrà a parare, mi aspetto dei risultati, ma
non so che cosa succeda tra input ed output. Il funzionamento di una
rete non è esprimibile con una formula matematica. </font>
</p>
<p style="font-style: normal;"><font size="3">SARTI – Nel nostro
lavoro di ingegneri ci sono queste cose che si vede che funzionano,
ma non si sa come siano fatte dentro.</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI – Senza
scendere nei dettagli: nel 1982 Hopfield presenta un modello
matematico di rete dove si ha l'emergere spontaneo di nuove capacità
computazionali dal comportamento collettivo di un gran numero di
semplici elementi di elaborazione. Le proprietà collettive del
modello producono una memoria associativa per il riconoscimento di
configurazioni corrotte ed il recupero di informazioni mancanti. Ogni
sistema fisico può essere considerato come un potenziale
dispositivo di memoria, se dispone di un certo numero di stati
stabili che fungano da attrattore per il sistema stesso. Quindi la
stabilità e la collocazione di tali attrattori sono proprietà
spontanee di sistemi costituiti da considerevoli quantità di
neuroni reciprocamente interagenti. Dunque il numero fa la
differenza. Il gran numero di dati genera ulteriormente calcolo. Il
calcolo produce numeri, ma anche i numeri possono spontaneamente
generare calcolo. Cos'è un attrattore? Prendiamo una pallina
su un piano inclinato che incontra una buca, e la sua energia
cinetica non basta a superare la buca: la pallina resta nella buca.
Per variare questo stato devo spendere energia, sollevando la
pallina. Un calo del potenziale costituisce un attrattore. Possiamo
definire potenziali non di energia, ma matematici ed anche di
informazione. I cali di potenziale diventano stati stabili.</font></p>
<p style="font-style: normal;"><font size="3">BELARDINELLI – Che
cosa significa stabile? Senza risposta al variare dell'input?</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI – Per
muovere la pallina devo superare una certa soglia, altrimenti la
pallina resta lì. </font>
</p>
<p style="font-style: normal;"><font size="3">Le reti di Kohonen sono
mappe auto organizzanti, con un algoritmo di apprendimento non
supervisionato, che ha dato luogo a molte applicazioni nei problemi
di classificazione. Le mappe sono reticoli di neuroni artificiali i
cui pesi sono continuamente adattati ai vettori presentati in
ingresso nel relativo insieme di addestramento. L'algoritmo può
essere descritto come un insieme di neuroni artificiali, ciascuno con
una precisa collocazione sulla mappa che rappresenta gli output: il
nodo avente un vettore di pesi più vicino ad un certo input è
dichiarato vincitore ed i pesi stessi vengono aggiornati in modo da
avvicinarli al vettore in ingresso, mentre i pesi dei nodi adiacenti
vengono modificati secondo la regola che più un nodo è
lontano dal nodo vincitore, meno marcata deve essere la variazione
dei suoi pesi (il vincitore piglia tutto!). Ripetendo il processo la
mappa riesce ad associare i nodi di uscita con i gruppi o schemi
ricorrenti nell'insieme dei dati in ingresso.</font></p>
<p style="font-style: normal;"><font size="3">Ci sono infine le reti ad
attrattori, dove l'attrattore viene esemplificato non da una buca, ma
da un'oscillazione. La loro dinamica, nel tempo, stabilisce un
assestamento in un particolare modo di oscillazione, che può
essere stazionario, variabile nel tempo oppure di tipo stocastico.
Queste reti sono utili per investigare la teoria dei sistemi dinamici
ed analizzarne le caratteristiche, ad esempio di stabilità o
robustezza. </font>
</p>
<p style="font-style: normal;"><font size="3">I pregi delle reti
neurali: i neuroni lavorano in parallelo e sono sistemi di tipo
statistico, per cui il cattivo funzionamento di una parte
difficilmente blocca l'insieme. I software di ultima generazione
richiedono comunque buone conoscenze statistiche: pur permettendo
all'utente di fare subito previsioni o classificazioni, il grado di
utilizzabilità mantiene i limiti del caso e non deve trarre in
inganno.</font></p>
<p style="font-style: normal;"><font size="3">I difetti: i modelli
prodotti dalle reti neurali non sono spiegabili in linguaggio
simbolico umano: vanno accettati così come sono (li
definiscono “blak box”), a differenza di un sistema
algoritmico dove si può esaminare passo per passo il percorso
che dall'input genera l'output.</font></p>
<p style="font-style: normal;"><font size="3">CASADIO – Non sono
d'accordo.</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI – Chiaro
che tu sai come funziona la rete, visto che la costruisci tu. </font>
</p>
<p style="font-style: normal;"><font size="3">CASADIO – Per questo
rispetto al cervello c'è un oceano.</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI –
D'accordo. Infine le reti sono predittive solo se le variabili
predittive sono scelte con cura. Per questo è importante
l'esperienza di chi opera. Non c'è modo di definire la rete
ottima: la riuscita dipende molto dall'esperienza del creatore della
rete. Gli esempi di utilizzo sono gli OCR, il riconoscimento dei
volti...</font></p>
<p style="font-style: normal;"><font size="3">CASADIO – Non ci
sono solo le reti neurali. Ci sono anche altri oggetti computazionali
più efficienti. Ma non dovevamo parlare del cervello?</font></p>
<p style="font-style: normal;"><font size="3">PARENTI – Nonostante
quello che disse Aristotele 2400 anni fa, continua l'illusione di
costruire la macchina pensante. Andiamo allora a vedere che cosa
dovrebbe essere. L'apprendimento computazionale non mi pare sia lo
stesso di cui parla Aristotele nel testo che vi ho inviato [vedi in
calce al resoconto]. Siete capaci di confutarlo?</font></p>
<p style="font-style: normal;"><font size="3">CASADIO – Il
conoscere, secondo la biologia, è una trasformazione.</font></p>
<p style="font-style: normal;"><font size="3">PARENTI – Quello è
il problema. Aristotele dice che la trasformazione è l'atto di
chi è imperfetto [incompiuto], mentre il conoscere è
atto di chi è perfetto [compiuto]. Cosa rispondi?</font></p>
<p style="font-style: normal;"><font size="3">FRATTINI – Non
dobbiamo parlare solo di conoscenza. I filosofi della mente dicono
che la coscienza è intenzionalità.</font></p>
<p style="font-style: normal;"><font size="3">PARENTI – Per questo
ho mandato un testo che parlasse della conoscenza in quanto tale.
Anche se ci vogliono, per i sensi, le trasformazioni.</font></p>
<p style="font-style: normal;"><font size="3">CASADIO – Ci
vogliono le definizioni di conoscere, coscienza e intelletto, prima
di addentrarci nella discussione.</font></p>
<p><br>
<br>
</p>
<p><font size="3">_______________________ </font>
</p>
<p><font size="3">TESTO DI ARISTOTELE E COMMENTO</font></p>
<p style="margin-bottom: 0cm;"><font size="3"><b>431a4</b> L'oggetto di
senso risulta ciò che fa passare la sensibilità dalla
potenza all'atto; infatti non subisce né è alterata.
Quindi questa è una specie diversa di processo: il movimento
infatti è atto di ciò che è imperfetto, invece
l'atto senza restrizioni è diverso, è atto di ciò
che è perfetto.</font></p>
<p style="margin-bottom: 0cm;"><br>
</p>
<p style="margin-bottom: 0cm;"><font size="3"><b>431a4</b> …
Dunque, afferma per prima cosa che <i>l'oggetto di senso risulta </i><span
 style="font-style: normal;">ciò
che fa passare </span><i>dalla potenza all'atto</i> <span
 style="font-style: normal;">la
parte sensitiva: </span><i>infatti</i> <span
 style="font-style: normal;">l'oggetto
</span><i>non</i> <span style="font-style: normal;">agisce sul senso
come un contrario agisce sul proprio contrario, in modo che qualcosa
sia perso dal senso, trasformandolo e alterandolo, ma l'oggetto di
senso lo riconduce soltanto dalla potenza all'atto; e per questo
Aristotele aggiunge che la sensibilità non </span><i>subisce
né è alterata</i> <span style="font-style: normal;">dall'oggetto
di senso, mediante un subire e un'alterazione, propriamente intesi,
cioè come quando uno dei contrari agisce sull'altro. E poiché
i processi delle realtà corporee, determinati nel libro della
</span><i>Fisica</i><a class="sdfootnoteanc" name="sdfootnote1anc"
 href="#sdfootnote1sym"><sup>1</sup></a><span
 style="font-style: normal;">,
sono passaggi da un contrario ad un altro, è chiaro che se si
dice che l'aver sensazione è un processo, è </span><i>una
specie di processo diversa</i> <span style="font-style: normal;">da
quella determinata nel libro della </span><i>Fisica</i><span
 style="font-style: normal;">:
quella è infatti l'atto di ciò che è in potenza
perché, cioè, ciò che recede da un contrario,
finché si muove, non raggiunge l'altro contrario che è
il termine del movimento, ma è in potenza ad esso e, poiché
tutto ciò che è in potenza, in quanto tale, è
imperfetto, allora quel </span><i>processo</i> <span
 style="font-style: normal;">è
</span><i>atto</i> <span style="font-style: normal;">di ciò che
è imperfetto; ma quest'altro processo è atto </span><i>di
ciò che è perfetto</i> <span style="font-style: normal;">(di
fatto è l'operazione di un senso che è già in
atto grazie alla propria rappresentazione, infatti percepire non si
addice che ad un senso che sia in atto), e perciò questo
processo è </span><i>del tutto diverso</i> <span
 style="font-style: normal;">da
quello fisico …</span></font></p>
<p style="margin-bottom: 0cm;"><br>
</p>
<p style="margin-left: 1.25cm; margin-bottom: 0cm;"><font size="3"><span
 style="font-style: normal;">da
TOMMASO D'AQUINO, </span><i>Lo specchio dell'anima – La
sentenza di Tommaso d'Aquino sul “De anima” di
Aristotele</i><span style="font-style: normal;">, a cura del Progetto
Tommaso, San Paolo, Cinisello Balsamo 2012, pag. 1033 per il testo di
Aristotele, pag. 1037 per il commento di Tommaso.</span></font></p>
<p style="margin-bottom: 0cm;"><br>
</p>
<div id="sdfootnote1">
<p class="sdfootnote" style="margin-bottom: 0.5cm;"><a
 class="sdfootnotesym" name="sdfootnote1sym" href="#sdfootnote1anc">1</a>Per
un riscontro di questo generico riferimento alla <i>Fisica</i><span
 style="font-style: normal;">, cfr. Aristotele, </span><i>Phys.</i><span
 style="font-style: normal;">, III, 200b12-202b29.</span></p>
</div>
</body>
</html>
